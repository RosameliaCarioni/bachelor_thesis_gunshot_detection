{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from methods_audio import data_handling\n",
    "from methods_audio import data_augmentation\n",
    "from methods_audio import denoising \n",
    "from methods_audio import model_performance_training\n",
    "from methods_audio import model_training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the following code, the best model (resulting from experiments) will be trained once and exported as final model. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_handling.get_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Read data (transforming file names into waves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(data_handling.read_in_data) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Get input for model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 18:51:25.140497: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "samples, labels = data_handling.extract_samples_labels(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Split data into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set_size = 0.30\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(samples, labels, test_size= validation_set_size, random_state=123)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation \n",
    "type_augmentation = 'signal'\n",
    "# denoising \n",
    "type_denoising= 'spectral'\n",
    "differentiation = True \n",
    "\n",
    "# Low pass filter \n",
    "low_pass_cutoff = 500 # this value will be used for experimentation, ranging from 500-4000. \n",
    "low_pass_order = 4 # this value will be used for experimentation \n",
    "\n",
    "# transforming data\n",
    "type_transformation = 'spectrogram' \n",
    "\n",
    "# model structure \n",
    "model_name = '01'\n",
    "location_model = 'data/models/' + model_name \n",
    "location_weights = 'data/models/weights' + model_name\n",
    "\n",
    "# training \n",
    "batch_size = 8 \n",
    "epoch = 20 \n",
    "\n",
    "# learning rate \n",
    "if (model_name == '01'):\n",
    "    learning_rate = 0.02661877777328162 # result from param optimization for Model 1 \n",
    "elif (model_name == '02'): \n",
    "    learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (type_augmentation == 'signal'):\n",
    "    x_train, y_train = data_augmentation.time_augmentation(x_train, y_train)\n",
    "elif(type_augmentation == 'spectrogram'):\n",
    "    # TODO: work out what to do  \n",
    "    x_train, y_train = data_augmentation.spectrogram_augmentaion(x_train, y_train)\n",
    "elif(type_augmentation == 'both'): \n",
    "    # TODO: sort this\n",
    "    pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Denoising "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (type_denoising== 'spectral'): \n",
    "    denoising.apply_spectral(x_train)\n",
    "    denoising.apply_spectral(x_valid)\n",
    "elif(type_denoising == 'low_pass'): \n",
    "    denoising.apply_low_pass(x_train, low_pass_cutoff, low_pass_order)\n",
    "    denoising.apply_low_pass(x_valid, low_pass_cutoff, low_pass_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Data transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data_handling.transform_data(x_train, type_transformation)\n",
    "x_valid = data_handling.transform_data(x_valid, type_transformation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Upload and compile model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(location_model)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=learning_rate), \n",
    "    loss=\"BinaryCrossentropy\", \n",
    "    metrics = ['accuracy', 'Recall', 'Precision'],\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = model_training(model, x_train, y_train, x_valid, y_train, batch_size, epoch)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Save weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(location_weights, overwrite = True, save_format = 'tf', options = None) # saving as TensorFlow format "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
