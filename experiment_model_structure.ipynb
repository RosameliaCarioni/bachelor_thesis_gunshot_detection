{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from methods_audio import data_handling\n",
    "from methods_audio import data_augmentation\n",
    "from methods_audio import denoising \n",
    "from methods_audio import model_performance_training\n",
    "from methods_audio import model_training\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get data (file names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_handling.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.shuffle_op._ShuffleDataset"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Read data (transforming file names into waves) <br>\n",
    "Additionally, the mean is removed and the data is normalized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(data_handling.read_in_data) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Get input for model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 18:51:25.140497: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "samples, labels = data_handling.extract_samples_labels(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Split data into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set_size = 0.30\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(samples, labels, test_size= validation_set_size, random_state=123)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Data Augmentation (on train set only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define type of augmentation to do. Options: signal, spectogram, both, none \n",
    "type_augmentation = 'signal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (type_augmentation == 'signal'):\n",
    "    x_train, y_train = data_augmentation.time_augmentation(x_train, y_train)\n",
    "elif(type_augmentation == 'spectrogram'):\n",
    "    # TODO: work out what to do  \n",
    "    x_train, y_train = data_augmentation.spectrogram_augmentaion(x_train, y_train)\n",
    "elif(type_augmentation == 'both'): \n",
    "    # TODO: sort this\n",
    "    pass "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Denoising (on train and validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define type of denoising to do. Options: spectral_gating, low_pass, none \n",
    "type_denoising= 'spectral'\n",
    "differentiation = True \n",
    "\n",
    "# For low pass filter:\n",
    "low_pass_cutoff = 500 # this value will be used for experimentation, ranging from 500-4000. \n",
    "low_pass_order = 4 # this value will be used for experimentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (type_denoising== 'spectral'): \n",
    "    denoising.apply_spectral(x_train)\n",
    "    denoising.apply_spectral(x_valid)\n",
    "elif(type_denoising == 'low_pass'): \n",
    "    denoising.apply_low_pass(x_train, cutoff, order)\n",
    "    denoising.apply_low_pass(x_valid, cutoff, order)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Transform data into Spectogram/Mel-spectogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define type of transformation to do. Options = spectrogram, mel_spectrogram, db_mel_spectrogram\n",
    "type_transformation = 'spectrogram' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data_handling.transform_data(x_train, type_transformation)\n",
    "x_valid = data_handling.transform_data(x_valid, type_transformation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Upload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which model to use: \n",
    "model_name = '01'\n",
    "location_model = 'data/models/' + model_name \n",
    "location_weights = 'data/models/weights' + model_name\n",
    "\n",
    "batch_size = 8 \n",
    "epoch = 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (model_name == '01'):\n",
    "    learning_rate = 0.02661877777328162 # result from param optimization for Model 1 \n",
    "elif (model_name == '02'): \n",
    "    learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(location_model)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=learning_rate), \n",
    "    loss=\"BinaryCrossentropy\", \n",
    "    metrics = ['accuracy', 'Recall', 'Precision'],\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Evaluate performance of the model by training it with K-Fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices, histories = model_performance_training.train_performance_k_fold(location_model, samples, labels, learning_rate, epoch, batch_size,type_augmentation, type_denoising, low_pass_cutoff, low_pass_order, type_transformation)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. If any certain model perform well, it can be trained and exported as final model using: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model, history = model_training(model, x_train, y_train, x_valid, y_train, batch_size, epoch)\n",
    "#model.save_weights(location_weights, overwrite = True, save_format = 'tf', options = None) # saving as TensorFlow format "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bach_thesis_4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
