{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rosameliacarioni/miniconda3/envs/bach_thesis_4/lib/python3.9/site-packages/tensorflow_io-0.32.0-py3.9-macosx-11.0-arm64.egg/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/Users/rosameliacarioni/miniconda3/envs/bach_thesis_4/lib/python3.9/site-packages/tensorflow_io-0.32.0-py3.9-macosx-11.0-arm64.egg/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: [\"[Errno 2] The file to load file system plugin from does not exist.: '/Users/rosameliacarioni/miniconda3/envs/bach_thesis_4/lib/python3.9/site-packages/tensorflow_io-0.32.0-py3.9-macosx-11.0-arm64.egg/tensorflow_io/python/ops/libtensorflow_io_plugins.so'\"]\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/Users/rosameliacarioni/miniconda3/envs/bach_thesis_4/lib/python3.9/site-packages/tensorflow_io-0.32.0-py3.9-macosx-11.0-arm64.egg/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/Users/rosameliacarioni/miniconda3/envs/bach_thesis_4/lib/python3.9/site-packages/tensorflow_io-0.32.0-py3.9-macosx-11.0-arm64.egg/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: [\"dlopen(/Users/rosameliacarioni/miniconda3/envs/bach_thesis_4/lib/python3.9/site-packages/tensorflow_io-0.32.0-py3.9-macosx-11.0-arm64.egg/tensorflow_io/python/ops/libtensorflow_io.so, 0x0006): tried: '/Users/rosameliacarioni/miniconda3/envs/bach_thesis_4/lib/python3.9/site-packages/tensorflow_io-0.32.0-py3.9-macosx-11.0-arm64.egg/tensorflow_io/python/ops/libtensorflow_io.so' (no such file)\"]\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from methods_audio import data_handling\n",
    "from methods_audio import data_augmentation\n",
    "from methods_audio import denoising \n",
    "from methods_audio import model_performance_training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get data (file names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data_handling.get_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Read data (transforming file names into waves) <br>\n",
    "Additionally, the mean is removed and the data is normalized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(data_handling.read_in_data) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Get input for model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 15:27:04.413786: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "samples, labels = data_handling.extract_samples_labels(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Split data into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set_size = 0.20\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(samples, labels, test_size= validation_set_size, random_state=123)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Data Augmentation (on train set only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define type of augmentation to do. Options: signal, spectogram, both, none \n",
    "type_augmentation = 'none'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Denoising (on train and validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define type of denoising to do. Options: spectral_gating, low_pass, none \n",
    "type_denoising= 'none'\n",
    "differentiation = False \n",
    "\n",
    "# For low pass filter:\n",
    "low_pass_cutoff = 500 # this value will be used for experimentation, ranging from 500-4000. \n",
    "low_pass_order = 4 # this value will be used for experimentation "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Transform data into Spectogram/Mel-spectogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define type of transformation to do. Options = spectrogram, mel_spectrogram, db_mel_spectrogram, mfcc, mfcc_delta\n",
    "type_transformation = 'mel_spectrogram' \n",
    "# mel_spectogram: expected shape=(None, 624, 129, 1), found shape=(None, 624, 128, 1)\n",
    "# mfcc: hape=(None, 624, 129, 1), found shape=(None, 13, 157)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Choose model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which model to use: \n",
    "number_model = 2\n",
    "\n",
    "batch_size = 8 \n",
    "epoch = 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (number_model == 1):\n",
    "    learning_rate = 0.02661877777328162 # result from param optimization for Model 1 \n",
    "elif (number_model == 2): \n",
    "    learning_rate = 0.01"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Evaluate performance of the model by training it with K-Fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rosameliacarioni/University/Thesis/code/methods_audio/model_performance_training.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train = np.array(x)[train.astype(int)]\n",
      "/Users/rosameliacarioni/University/Thesis/code/methods_audio/model_performance_training.py:90: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_valid = np.array(x)[test.astype(int)]\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "356/356 [==============================] - 18s 47ms/step - loss: 0.4133 - accuracy: 0.8357 - recall: 0.8277 - precision: 0.8401 - val_loss: 0.4403 - val_accuracy: 0.8115 - val_recall: 0.9014 - val_precision: 0.7637\n",
      "Epoch 2/5\n",
      "356/356 [==============================] - 16s 44ms/step - loss: 0.2796 - accuracy: 0.8896 - recall: 0.8764 - precision: 0.8993 - val_loss: 0.3020 - val_accuracy: 0.8931 - val_recall: 0.9014 - val_precision: 0.8864\n",
      "Epoch 3/5\n",
      "356/356 [==============================] - 16s 45ms/step - loss: 0.2152 - accuracy: 0.9173 - recall: 0.9061 - precision: 0.9264 - val_loss: 0.3298 - val_accuracy: 0.8833 - val_recall: 0.8451 - val_precision: 0.9146\n",
      "Epoch 4/5\n",
      "356/356 [==============================] - 17s 47ms/step - loss: 0.1536 - accuracy: 0.9420 - recall: 0.9273 - precision: 0.9549 - val_loss: 0.4429 - val_accuracy: 0.8312 - val_recall: 0.9408 - val_precision: 0.7714\n",
      "Epoch 5/5\n",
      "356/356 [==============================] - 16s 45ms/step - loss: 0.1123 - accuracy: 0.9599 - recall: 0.9499 - precision: 0.9690 - val_loss: 0.2972 - val_accuracy: 0.8931 - val_recall: 0.9155 - val_precision: 0.8760\n",
      "accuracy: 89.31%\n",
      "23/23 [==============================] - 1s 41ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m confusion_matrices, histories \u001b[39m=\u001b[39m model_performance_training\u001b[39m.\u001b[39;49mtrain_performance_k_fold(number_model, samples, labels, learning_rate, epoch, batch_size,type_augmentation, type_denoising, low_pass_cutoff, low_pass_order, type_transformation)\n",
      "File \u001b[0;32m~/University/Thesis/code/methods_audio/model_performance_training.py:117\u001b[0m, in \u001b[0;36mtrain_performance_k_fold\u001b[0;34m(number_model, x, y, learning_rate, epoch, batch_size, type_augmentation, type_denoising, low_pass_cutoff, low_pass_order, type_transformation)\u001b[0m\n\u001b[1;32m    114\u001b[0m     x_valid_list \u001b[39m=\u001b[39mdenoising\u001b[39m.\u001b[39mapply_low_pass(x_valid_list, low_pass_cutoff, low_pass_order)\n\u001b[1;32m    116\u001b[0m \u001b[39m# 7. Pad samples so that they all have the same length and transform data to frequency domain\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m x_train_list \u001b[39m=\u001b[39m data_handling\u001b[39m.\u001b[39;49mtransform_data(x_train_list, type_transformation)\n\u001b[1;32m    118\u001b[0m x_valid_list \u001b[39m=\u001b[39m data_handling\u001b[39m.\u001b[39mtransform_data(x_valid_list, type_transformation)\n\u001b[1;32m    120\u001b[0m \u001b[39m# 8. Transform data from list to np.numpy \u001b[39;00m\n",
      "File \u001b[0;32m~/University/Thesis/code/methods_audio/data_handling.py:173\u001b[0m, in \u001b[0;36mtransform_data\u001b[0;34m(waves, type_transformation)\u001b[0m\n\u001b[1;32m    171\u001b[0m    \u001b[39mfor\u001b[39;00m wave \u001b[39min\u001b[39;00m waves: \n\u001b[1;32m    172\u001b[0m         wave \u001b[39m=\u001b[39m pad_sample(wave)\n\u001b[0;32m--> 173\u001b[0m         transformed_wave \u001b[39m=\u001b[39m convert_to_mel_spectrogram(wave)\n\u001b[1;32m    174\u001b[0m         transformed_signals\u001b[39m.\u001b[39mappend(transformed_wave)\n\u001b[1;32m    176\u001b[0m \u001b[39melif\u001b[39;00m (type_transformation \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdb_mel_spectrogram\u001b[39m\u001b[39m'\u001b[39m): \n",
      "File \u001b[0;32m~/University/Thesis/code/methods_audio/data_handling.py:106\u001b[0m, in \u001b[0;36mconvert_to_mel_spectrogram\u001b[0;34m(wave)\u001b[0m\n\u001b[1;32m    104\u001b[0m number_mels_filterbanks \u001b[39m=\u001b[39m \u001b[39m128\u001b[39m \n\u001b[1;32m    105\u001b[0m \u001b[39m# 1. Fast fourier transform \u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m spectrogram \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49msignal\u001b[39m.\u001b[39;49mstft(wave, frame_length\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m, frame_step\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m)  \u001b[39m# Paper: 'Automated detection of gunshots in tropical forests using CNN' \u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[39m# 2. Obtain the magnitude of the STFT\u001b[39;00m\n\u001b[1;32m    108\u001b[0m spectrogram \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mabs(spectrogram)\n",
      "File \u001b[0;32m~/miniconda3/envs/bach_thesis_4/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/bach_thesis_4/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/bach_thesis_4/lib/python3.9/site-packages/tensorflow/python/ops/signal/spectral_ops.py:92\u001b[0m, in \u001b[0;36mstft\u001b[0;34m(signals, frame_length, frame_step, fft_length, window_fn, pad_end, name)\u001b[0m\n\u001b[1;32m     88\u001b[0m   framed_signals \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m window\n\u001b[1;32m     90\u001b[0m \u001b[39m# fft_ops.rfft produces the (fft_length/2 + 1) unique components of the\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[39m# FFT of the real windowed signals in framed_signals.\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m \u001b[39mreturn\u001b[39;00m fft_ops\u001b[39m.\u001b[39;49mrfft(framed_signals, [fft_length])\n",
      "File \u001b[0;32m~/miniconda3/envs/bach_thesis_4/lib/python3.9/site-packages/tensorflow/python/ops/signal/fft_ops.py:139\u001b[0m, in \u001b[0;36m_rfft_wrapper.<locals>._rfft\u001b[0;34m(input_tensor, fft_length, name)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mif\u001b[39;00m fft_length_static \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m   fft_length \u001b[39m=\u001b[39m fft_length_static\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m fft_fn(input_tensor, fft_length, Tcomplex\u001b[39m=\u001b[39;49mcomplex_dtype, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/bach_thesis_4/lib/python3.9/site-packages/tensorflow/python/ops/gen_spectral_ops.py:1140\u001b[0m, in \u001b[0;36mrfft\u001b[0;34m(input, fft_length, Tcomplex, name)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m   1139\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1140\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m   1141\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mRFFT\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, \u001b[39minput\u001b[39;49m, fft_length, \u001b[39m\"\u001b[39;49m\u001b[39mTcomplex\u001b[39;49m\u001b[39m\"\u001b[39;49m, Tcomplex)\n\u001b[1;32m   1142\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   1143\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "confusion_matrices, histories = model_performance_training.train_performance_k_fold(number_model, samples, labels, learning_rate, epoch, batch_size,type_augmentation, type_denoising, low_pass_cutoff, low_pass_order, type_transformation)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bach_thesis_4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
